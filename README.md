# ğŸš€ DataFlow Supply Chain Intelligence Platform

<div align="center">

![Supply Chain](https://img.shields.io/badge/Supply_Chain-Real--Time-blue)
![Data Engineering](https://img.shields.io/badge/Data_Engineering-Pipeline-green)
![Python](https://img.shields.io/badge/Python-3.12-yellow)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)
![License](https://img.shields.io/badge/License-MIT-red)

**Real-time supply chain intelligence platform with predictive analytics and automated data pipelines**

[Features](#-features) â€¢ [Architecture](#-architecture) â€¢ [Tech Stack](#-tech-stack) â€¢ [Quick Start](#-quick-start) â€¢ [Screenshots](#-screenshots)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Tech Stack](#-tech-stack)
- [Project Structure](#-project-structure)
- [Quick Start](#-quick-start)
- [Components](#-components)
- [Screenshots](#-screenshots)
- [Future Enhancements](#-future-enhancements)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

**DataFlow Supply Chain Platform** is an end-to-end data engineering project that demonstrates real-time supply chain intelligence capabilities. The platform processes and analyzes logistics data across orders, shipments, inventory, and suppliers to provide actionable insights for supply chain optimization.

### Key Highlights

- ğŸ—ï¸ **Production-grade infrastructure** with Docker Compose
- ğŸ“Š **Real-time streaming** with Apache Kafka
- âš™ï¸ **Workflow orchestration** with Apache Airflow
- ğŸ“ˆ **Interactive dashboards** with Streamlit
- ğŸ—„ï¸ **Scalable data architecture** with Star Schema
- ğŸ”„ **Complete ETL pipeline** from ingestion to visualization

---

## âœ¨ Features

### Data Engineering
- âœ… **Multi-source data ingestion** (PostgreSQL, MongoDB, Kafka)
- âœ… **Real-time streaming pipeline** with Kafka producers/consumers
- âœ… **Batch processing** with scheduled ETL jobs
- âœ… **Data quality validation** and monitoring
- âœ… **Star schema data warehouse** design

### Analytics & Visualization
- âœ… **Real-time KPI dashboards** (Orders, Revenue, Delivery Performance)
- âœ… **Interactive charts** (Bar, Pie, Line, Maps)
- âœ… **Geospatial analysis** with shipment tracking
- âœ… **Auto-refreshing metrics** from live data streams

### Infrastructure
- âœ… **Containerized services** with Docker Compose
- âœ… **Scalable architecture** supporting 1000+ orders/day
- âœ… **Monitoring & logging** capabilities
- âœ… **CI/CD ready** structure

---

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA SOURCES                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  PostgreSQL  â”‚  MongoDB  â”‚  Kafka Stream  â”‚  External APIs      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INGESTION LAYER                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Kafka Producers (Real-time Orders)                           â”‚
â”‚  â€¢ Data Generators (Suppliers, Products, Inventory)             â”‚
â”‚  â€¢ API Connectors                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PROCESSING LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Kafka Consumers (Stream Processing)                           â”‚
â”‚  â€¢ Airflow DAGs (Batch ETL)                                      â”‚
â”‚  â€¢ Data Transformation & Validation                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STORAGE LAYER                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ PostgreSQL (Raw, Staging, Analytics)                          â”‚
â”‚  â€¢ MongoDB (Product Catalog)                                     â”‚
â”‚  â€¢ Redis (Caching)                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PRESENTATION LAYER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Streamlit Dashboard (Real-time Metrics)                       â”‚
â”‚  â€¢ FastAPI (REST API - Optional)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### Core Technologies

| Category | Technologies |
|----------|-------------|
| **Languages** | Python 3.12 |
| **Orchestration** | Apache Airflow 2.10 |
| **Streaming** | Apache Kafka 7.5, Zookeeper |
| **Databases** | PostgreSQL 15, MongoDB 7.0, Redis 7.0 |
| **Visualization** | Streamlit, Plotly |
| **Containerization** | Docker, Docker Compose |
| **Data Processing** | Pandas, SQLAlchemy |
| **Testing** | Pytest |

### Python Libraries
```
confluent-kafka==2.3.0
sqlalchemy==2.0.25
pandas==2.1.4
streamlit==1.30.0
plotly==5.18.0
faker==22.0.0
```

---

## ğŸ“ Project Structure
```
dataflow-supply-chain/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/          # Data generation & loading
â”‚   â”œâ”€â”€ streaming/          # Kafka producers/consumers
â”‚   â”œâ”€â”€ transformation/     # Data transformations
â”‚   â”œâ”€â”€ warehouse/          # Star schema logic
â”‚   â””â”€â”€ utils/              # DB connectors, logging
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/               # ETL workflow definitions
â”‚
â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ main_dashboard.py   # Streamlit dashboard
â”‚   â”œâ”€â”€ pages/              # Multi-page layouts
â”‚   â””â”€â”€ components/         # Reusable UI components
â”‚
â”œâ”€â”€ kafka/
â”‚   â”œâ”€â”€ producers/          # Order stream producers
â”‚   â””â”€â”€ consumers/          # Stream processors
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â””â”€â”€ docker/
â”‚       â”œâ”€â”€ docker-compose.yml
â”‚       â””â”€â”€ init-scripts/   # Database initialization
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Bronze layer
â”‚   â”œâ”€â”€ processed/          # Silver layer
â”‚   â””â”€â”€ analytics/          # Gold layer
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml         # Application configuration
â”‚
â”œâ”€â”€ producer.py             # Kafka order producer
â”œâ”€â”€ consumer.py             # Kafka order consumer
â”œâ”€â”€ check_data.py           # Database verification
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Python 3.11+
- 8GB RAM minimum
- WSL2 (for Windows users)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/dataflow-supply-chain.git
cd dataflow-supply-chain
```

2. **Create virtual environment**
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Start infrastructure**
```bash
docker-compose up -d
```

Wait 2-3 minutes for all services to start.

5. **Initialize database & load data**
```bash
python load_data.py
```

6. **Start Kafka streaming** (Optional - for real-time demo)

Terminal 1 - Producer:
```bash
python3 producer.py
```

Terminal 2 - Consumer:
```bash
python3 consumer.py
```

7. **Launch dashboard**
```bash
streamlit run dashboards/main_dashboard.py
```

Open browser: `http://localhost:8501`

---

## ğŸ”§ Components

### 1. Data Generation
- Generates realistic supply chain data (Orders, Products, Suppliers)
- Faker library for realistic names and locations
- Configurable data volumes

### 2. Real-time Streaming
- **Producer**: Streams new orders every 3 seconds
- **Consumer**: Processes and stores orders in PostgreSQL
- **Kafka UI**: Monitor topics at `http://localhost:8080`

### 3. Batch Processing
- **Airflow DAGs**: Scheduled ETL pipelines
- **Airflow UI**: `http://localhost:8081` (admin/admin)
- Daily transformations from Raw â†’ Staging â†’ Analytics

### 4. Data Warehouse
- **Star Schema** design with fact and dimension tables
- **Layers**: Bronze (raw) â†’ Silver (cleaned) â†’ Gold (analytics)
- Optimized for analytical queries

### 5. Dashboard
- Real-time KPIs and metrics
- Interactive charts and maps
- Auto-refresh every 30 seconds

---

## ğŸ“¸ Screenshots

### Dashboard Overview
*Real-time supply chain metrics and KPIs*

![Dashboard](docs/screenshots/dashboard.png)

### Kafka Streaming
*Live order processing*

![Streaming](docs/screenshots/streaming.png)

### Airflow Pipeline
*Automated ETL workflows*

![Airflow](docs/screenshots/airflow.png)

---

## ğŸ”® Future Enhancements

- [ ] ML-based demand forecasting
- [ ] Delivery time prediction model
- [ ] Anomaly detection system
- [ ] Great Expectations data quality framework
- [ ] Spark for large-scale processing
- [ ] CI/CD pipeline with GitHub Actions
- [ ] Cloud deployment (AWS/Azure)

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

## ğŸ‘¤ Author

**Buthainah**

- GitHub: [@Buthainah3524](https://github.com/Buthainah3524)

---

## ğŸ“§ Contact

For questions or collaboration opportunities, feel free to reach out!

- ğŸ“§ Email: [Contact via GitHub](https://github.com/Buthainah3524)
- ğŸ™ GitHub: [@Buthainah3524](https://github.com/Buthainah3524)

---

## ğŸ™ Acknowledgments

- Inspired by real-world supply chain challenges
- Built as a Data Engineering portfolio project
- Special thanks to the open-source community

---

<div align="center">

**â­ Star this repo if you find it helpful!**

Made with â¤ï¸ for Data Engineering Excellence

</div>